"""
é‡å­å¹¶è¡Œå¤„ç†å™¨ - é›†æˆåˆ°Tavilyé¡¹ç›®
åŸºäºwuyueé‡å­æ¡†æ¶å®ç°å¤šå…¬å¸å¹¶è¡Œåˆ†æ
"""

import asyncio
import logging
import os
import json
import math
import numpy as np
from datetime import datetime
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor

# å¯¼å…¥wuyueé‡å­æ¡†æ¶
from wuyue_machine_learning.encoding import AmplitudeEncoding, AngleEncoding
from wuyue.register.quantumregister import QuantumRegister
from wuyue.register.classicalregister import ClassicalRegister
from wuyue.circuit.circuit import QuantumCircuit
from wuyue.element.gate import H, RX, RY, RZ, CNOT, CZ, MEASURE
from wuyue.backend import Backend

# å¯¼å…¥Tavilyç»„ä»¶
from ..graph import Graph

logger = logging.getLogger(__name__)


class QuantumParallelProcessor:
    """
    é‡å­å¹¶è¡Œå¤„ç†å™¨
    ç»“åˆTavilyçš„é«˜è´¨é‡æ•°æ®æ”¶é›†å’Œé‡å­å¹¶è¡Œè®¡ç®—èƒ½åŠ›
    """
    
    def __init__(self, max_companies: int = 8, n_layers: int = 3, shots: int = 1000):
        """
        åˆå§‹åŒ–é‡å­å¹¶è¡Œå¤„ç†å™¨

        Args:
            max_companies: æ”¯æŒçš„æœ€å¤§å…¬å¸æ•°é‡
            n_layers: é‡å­çº¿è·¯å±‚æ•°
            shots: é‡å­æµ‹é‡æ¬¡æ•°
        """
        self.max_companies = max_companies
        self.n_layers = n_layers
        self.shots = shots

        # é‡å­å‚æ•°
        self.n_qubits = math.ceil(math.log2(max_companies))  # å…¬å¸ç´¢å¼•é‡å­æ¯”ç‰¹
        self.feature_qubits = 4  # ç‰¹å¾é‡å­æ¯”ç‰¹
        self.total_qubits = self.n_qubits + self.feature_qubits

        # é‡å­åç«¯ - å»¶è¿Ÿåˆå§‹åŒ–
        self.backend = None
        self._initialize_backend()

        # çŸ¥è¯†åº“è®¾ç½®
        self._setup_knowledge_base()

        logger.info(f"ğŸ”¬ é‡å­å¹¶è¡Œå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ: {self.total_qubits}é‡å­æ¯”ç‰¹, {n_layers}å±‚, {shots}æ¬¡æµ‹é‡")

    def _initialize_backend(self):
        """åˆå§‹åŒ–é‡å­åç«¯"""
        try:
            self.backend = Backend.get_device()
            logger.debug("é‡å­åç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"é‡å­åç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.backend = None
    
    def _setup_knowledge_base(self):
        """è®¾ç½®çŸ¥è¯†åº“ç›®å½•"""
        self.knowledge_base_dir = "knowledge_base"
        self.company_reports_dir = os.path.join(self.knowledge_base_dir, "company_reports")
        self.quantum_metadata_dir = os.path.join(self.knowledge_base_dir, "quantum_metadata")
        self.batch_results_dir = os.path.join(self.knowledge_base_dir, "batch_results")
        
        for directory in [self.knowledge_base_dir, self.company_reports_dir, 
                         self.quantum_metadata_dir, self.batch_results_dir]:
            os.makedirs(directory, exist_ok=True)
    
    async def quantum_parallel_analyze(self, companies_data: List[Dict[str, str]], 
                                     websocket_manager=None, job_id=None) -> Dict[str, Any]:
        """
        é‡å­å¹¶è¡Œåˆ†æå¤šå®¶å…¬å¸
        
        Args:
            companies_data: [{"name": "ç‰¹æ–¯æ‹‰", "industry": "æ±½è½¦", "url": "..."}, ...]
            websocket_manager: WebSocketç®¡ç†å™¨
            job_id: ä»»åŠ¡ID
        """
        logger.info(f"ğŸš€ å¼€å§‹é‡å­å¹¶è¡Œåˆ†æ {len(companies_data)} å®¶å…¬å¸...")
        
        if websocket_manager and job_id:
            await websocket_manager.send_status_update(
                job_id, 
                status="processing", 
                message=f"ğŸ”¬ Starting quantum parallel analysis of {len(companies_data)} companies"
            )
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨Tavilyå¹¶è¡Œæ”¶é›†é«˜è´¨é‡æ•°æ®
            logger.info("ğŸ“Š é˜¶æ®µ1: ä½¿ç”¨Tavilyæ”¶é›†å…¬å¸æ•°æ®...")
            tavily_data = await self._collect_tavily_data(companies_data, websocket_manager, job_id)
            
            # ç¬¬äºŒé˜¶æ®µï¼šé‡å­ç¼–ç å’Œå¹¶è¡Œå¤„ç†
            logger.info("âš¡ é˜¶æ®µ2: é‡å­ç¼–ç å’Œå¹¶è¡Œè®¡ç®—...")
            quantum_results = await self._quantum_process(tavily_data, websocket_manager, job_id)
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šèåˆåˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
            logger.info("ğŸ§  é˜¶æ®µ3: èåˆåˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ...")
            final_reports = await self._generate_enhanced_reports(tavily_data, quantum_results, websocket_manager, job_id)
            
            # ç¬¬å››é˜¶æ®µï¼šä¿å­˜åˆ°çŸ¥è¯†åº“
            logger.info("ğŸ’¾ é˜¶æ®µ4: ä¿å­˜åˆ°çŸ¥è¯†åº“...")
            batch_summary = await self._save_to_knowledge_base(final_reports, companies_data)
            
            result = {
                "successful_reports": final_reports,
                "failed_companies": [],
                "batch_summary": batch_summary,
                "quantum_metadata": {
                    "total_qubits": self.total_qubits,
                    "quantum_layers": self.n_layers,
                    "measurement_shots": self.shots,
                    "quantum_advantage_enabled": True
                }
            }
            
            if websocket_manager and job_id:
                await websocket_manager.send_status_update(
                    job_id,
                    status="completed",
                    message=f"ğŸ‰ Quantum parallel analysis completed for {len(companies_data)} companies",
                    result=result
                )
            
            logger.info("âœ… é‡å­å¹¶è¡Œåˆ†æå®Œæˆï¼")
            return result
            
        except Exception as e:
            logger.error(f"âŒ é‡å­å¹¶è¡Œåˆ†æå¤±è´¥: {e}")
            if websocket_manager and job_id:
                await websocket_manager.send_status_update(
                    job_id, status="error", message=f"Quantum analysis failed: {str(e)}"
                )
            raise e
    
    async def _collect_tavily_data(self, companies_data: List[Dict[str, str]], 
                                 websocket_manager, job_id) -> Dict[str, Any]:
        """ä½¿ç”¨Tavilyå¹¶è¡Œæ”¶é›†å…¬å¸æ•°æ®"""
        if websocket_manager and job_id:
            await websocket_manager.send_status_update(
                job_id, status="processing", 
                message="ğŸ“Š Collecting high-quality data using Tavily..."
            )
        
        # å¹¶è¡Œæ‰§è¡ŒTavilyåˆ†æ
        tasks = []
        for i, company_data in enumerate(companies_data):
            task = self._run_tavily_analysis(company_data, i+1, len(companies_data))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        tavily_data = {}
        for i, result in enumerate(results):
            company_name = companies_data[i]["name"]
            if isinstance(result, Exception):
                logger.error(f"âŒ Tavilyåˆ†æå¤±è´¥ {company_name}: {result}")
                # åˆ›å»ºé»˜è®¤æ•°æ®
                tavily_data[company_name] = {
                    "report": f"Analysis failed for {company_name}",
                    "company_data": {},
                    "financial_data": {},
                    "error": str(result)
                }
            else:
                tavily_data[company_name] = result
        
        return tavily_data
    
    async def _run_tavily_analysis(self, company_data: Dict[str, str], 
                                 company_index: int, total_companies: int) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªå…¬å¸çš„Tavilyåˆ†æ"""
        company_name = company_data["name"]
        logger.info(f"ğŸ” åˆ†æ {company_name} ({company_index}/{total_companies})")
        
        # åˆ›å»ºTavily Graphå®ä¾‹
        graph = Graph(
            company=company_name,
            url=company_data.get("company_url", ""),
            industry=company_data.get("industry", ""),
            hq_location=company_data.get("hq_location", ""),
            websocket_manager=None,  # é¿å…WebSocketå†²çª
            job_id=None
        )
        
        # æ‰§è¡ŒTavilyåˆ†æ
        state = {}
        async for s in graph.run(thread={}):
            state.update(s)
        
        # æå–å…³é”®æ•°æ®
        report_content = state.get('report') or (state.get('editor') or {}).get('report', '')
        
        return {
            "company_name": company_name,
            "report": report_content,
            "company_data": state.get('company_data', {}),
            "financial_data": state.get('financial_data', {}),
            "industry_data": state.get('industry_data', {}),
            "news_data": state.get('news_data', {}),
            "references": state.get('references', []),
            "full_state": state
        }
    
    async def _quantum_process(self, tavily_data: Dict[str, Any],
                             websocket_manager, job_id) -> Dict[str, Any]:
        """é‡å­ç¼–ç å’Œå¹¶è¡Œå¤„ç† - ä½¿ç”¨single_agentçš„æ­£ç¡®æ–¹å¼"""
        if websocket_manager and job_id:
            await websocket_manager.send_status_update(
                job_id, status="processing",
                message="âš¡ Quantum encoding and parallel processing..."
            )

        # è½¬æ¢ä¸ºsingle_agentæ ¼å¼çš„å…¬å¸æ•°æ®
        companies_data = []
        for company_name, data in tavily_data.items():
            # ä»Tavilyæ•°æ®ä¸­æå–å› å­ä¿¡æ¯
            factors = self._extract_factors_from_tavily_data(data)
            companies_data.append({
                "name": company_name,
                "factors": factors,
                "tavily_data": data
            })

        # ä½¿ç”¨single_agentçš„é‡å­ç¼–ç æ–¹å¼ - ä¸€ä¸ªé‡å­çº¿è·¯å¤„ç†æ‰€æœ‰å…¬å¸
        encoded_qc = self._encode_all_companies_to_single_circuit(companies_data)

        # æ„å»ºåˆ†æçº¿è·¯ï¼ˆåŸºäºsingle_agentçš„æ–¹å¼ï¼‰
        analysis_qc = self._create_analysis_circuit(encoded_qc)

        # æ‰§è¡Œé‡å­è®¡ç®— - åªè°ƒç”¨ä¸€æ¬¡ï¼
        measurement_results = self._execute_single_quantum_circuit(analysis_qc)

        # åˆ†æé‡å­ç»“æœ
        quantum_analysis = self._analyze_quantum_results(measurement_results, companies_data)

        return quantum_analysis

    def _extract_factors_from_tavily_data(self, tavily_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»Tavilyæ•°æ®ä¸­æå–å› å­ä¿¡æ¯ï¼Œè½¬æ¢ä¸ºsingle_agentæ ¼å¼"""
        factors = []

        # ä»æŠ¥å‘Šé•¿åº¦æå–ä¿¡æ¯ä¸°å¯Œåº¦å› å­
        report_length = len(tavily_data.get('report', ''))
        factors.append({
            "name": "ä¿¡æ¯ä¸°å¯Œåº¦",
            "value": min(report_length / 1000.0, 10.0),  # æ ‡å‡†åŒ–åˆ°0-10
            "weight": 0.2
        })

        # ä»æ•°æ®æºæ•°é‡æå–å¯ä¿¡åº¦å› å­
        references_count = len(tavily_data.get('references', []))
        factors.append({
            "name": "æ•°æ®æºå¯ä¿¡åº¦",
            "value": min(references_count / 2.0, 10.0),  # æ ‡å‡†åŒ–åˆ°0-10
            "weight": 0.25
        })

        # ä»è´¢åŠ¡æ•°æ®æå–è´¢åŠ¡å¥åº·åº¦å› å­
        financial_data = tavily_data.get('financial_data', {})
        financial_score = len(str(financial_data)) / 100.0  # ç®€å•çš„è´¢åŠ¡æ•°æ®ä¸°å¯Œåº¦
        factors.append({
            "name": "è´¢åŠ¡å¥åº·åº¦",
            "value": min(financial_score, 10.0),
            "weight": 0.3
        })

        # ä»æ–°é—»æ•°æ®æå–å¸‚åœºæ´»è·ƒåº¦å› å­
        news_data = tavily_data.get('news_data', {})
        news_activity = len(str(news_data)) / 100.0
        factors.append({
            "name": "å¸‚åœºæ´»è·ƒåº¦",
            "value": min(news_activity, 10.0),
            "weight": 0.25
        })

        return factors

    def _encode_all_companies_to_single_circuit(self, companies_data: List[Dict[str, Any]]) -> QuantumCircuit:
        """
        å°†æ‰€æœ‰å…¬å¸ç¼–ç åˆ°å•ä¸ªé‡å­çº¿è·¯ä¸­ - single_agentçš„æ­£ç¡®æ–¹å¼
        è¿™æ˜¯çœŸæ­£çš„é‡å­å¹¶è¡Œï¼šä¸€ä¸ªé‡å­çº¿è·¯åŒæ—¶å¤„ç†æ‰€æœ‰å…¬å¸
        """
        n_companies = len(companies_data)
        if n_companies > self.max_companies:
            raise ValueError(f"å…¬å¸æ•°é‡ {n_companies} è¶…è¿‡æœ€å¤§æ”¯æŒæ•°é‡ {self.max_companies}")

        # åˆ›å»ºé‡å­å¯„å­˜å™¨
        qreg = QuantumRegister(self.total_qubits)
        creg = ClassicalRegister(self.total_qubits)
        qc = QuantumCircuit(qreg, creg)

        # 1. åˆ›å»ºå…¬å¸ç´¢å¼•çš„å åŠ æ€ - å…³é”®ï¼šæ‰€æœ‰å…¬å¸åŒæ—¶å­˜åœ¨ï¼
        for i in range(self.n_qubits):
            qc.add(H, qreg[i])  # |00âŸ© + |01âŸ© + |10âŸ© + |11âŸ©

        # 2. ä¸ºæ¯ä¸ªå…¬å¸ç¼–ç ç‰¹å¾æ•°æ®åˆ°åŒä¸€ä¸ªé‡å­ç³»ç»Ÿ
        for company_idx, company_data in enumerate(companies_data):
            self._encode_single_company_to_circuit(qc, qreg, company_idx, company_data)

        logger.info(f"âœ… æˆåŠŸå°† {n_companies} å®¶å…¬å¸ç¼–ç åˆ°å•ä¸ªé‡å­çº¿è·¯ä¸­")
        return qc

    def _encode_single_company_to_circuit(self, qc: QuantumCircuit, qreg: QuantumRegister,
                                        company_idx: int, company_data: Dict[str, Any]):
        """
        å°†å•ä¸ªå…¬å¸çš„æ•°æ®ç¼–ç åˆ°é‡å­çº¿è·¯ä¸­ - åŸºäºsingle_agentçš„æ–¹æ³•
        """
        factors = company_data.get('factors', [])

        # æå–å› å­ç‰¹å¾
        features = self._extract_features_from_factors(factors)

        # ä½¿ç”¨è§’åº¦ç¼–ç å°†ç‰¹å¾ç¼–ç åˆ°ç‰¹å¾é‡å­æ¯”ç‰¹ä¸Š
        for feature_idx, feature_value in enumerate(features[:self.feature_qubits]):
            target_qubit = self.n_qubits + feature_idx

            # åˆ›å»ºå—æ§æ—‹è½¬é—¨ï¼Œåªæœ‰å½“å…¬å¸ç´¢å¼•åŒ¹é…æ—¶æ‰åº”ç”¨
            control_qubits = self._get_control_qubits_for_company(company_idx)

            # åº”ç”¨å—æ§RYé—¨ç¼–ç ç‰¹å¾å€¼
            self._apply_controlled_rotation(qc, qreg, control_qubits, target_qubit, feature_value)

    def _extract_features_from_factors(self, factors: List[Dict[str, Any]]) -> List[float]:
        """
        ä»å› å­æ•°æ®ä¸­æå–ç‰¹å¾å‘é‡ - åŸºäºsingle_agentçš„æ–¹æ³•
        """
        features = []

        # æå–ä¸»è¦ç‰¹å¾
        for factor in factors:
            value = factor.get('value', 0.0)
            weight = factor.get('weight', 0.0)

            # ç‰¹å¾å·¥ç¨‹ï¼šç»“åˆå€¼å’Œæƒé‡
            weighted_value = value * weight
            features.append(weighted_value)

        # å¡«å……åˆ°å›ºå®šé•¿åº¦
        while len(features) < self.feature_qubits:
            features.append(0.0)

        # æ ‡å‡†åŒ–åˆ° [0, 2Ï€] èŒƒå›´ï¼ˆé€‚åˆè§’åº¦ç¼–ç ï¼‰
        features = np.array(features[:self.feature_qubits])
        if np.max(np.abs(features)) > 0:
            features = (features - np.min(features)) / (np.max(features) - np.min(features)) * 2 * np.pi

        return features.tolist()

    def _get_control_qubits_for_company(self, company_idx: int) -> List[int]:
        """
        è·å–å…¬å¸ç´¢å¼•å¯¹åº”çš„æ§åˆ¶é‡å­æ¯”ç‰¹ - åŸºäºsingle_agentçš„æ–¹æ³•
        """
        binary_repr = format(company_idx, f'0{self.n_qubits}b')
        control_qubits = []

        for i, bit in enumerate(binary_repr):
            if bit == '1':
                control_qubits.append(i)

        return control_qubits

    def _apply_controlled_rotation(self, qc: QuantumCircuit, qreg: QuantumRegister,
                                 control_qubits: List[int], target_qubit: int, angle: float):
        """
        åº”ç”¨å—æ§æ—‹è½¬é—¨ - åŸºäºsingle_agentçš„æ–¹æ³•
        """
        if len(control_qubits) == 0:
            # æ— æ§åˆ¶ä½ï¼Œç›´æ¥åº”ç”¨æ—‹è½¬é—¨
            qc.add(RY, qreg[target_qubit], paras=[angle])
        elif len(control_qubits) == 1:
            # å•æ§åˆ¶ä½
            qc.add(RY, qreg[target_qubit], qreg[control_qubits[0]], paras=[angle])
        else:
            # å¤šæ§åˆ¶ä½ï¼Œç®€åŒ–å¤„ç†
            for ctrl in control_qubits:
                qc.add(RY, qreg[target_qubit], qreg[ctrl], paras=[angle / len(control_qubits)])

    def _create_analysis_circuit(self, encoded_qc: QuantumCircuit) -> QuantumCircuit:
        """
        åˆ›å»ºåˆ†æé‡å­çº¿è·¯ - åŸºäºsingle_agentçš„æ–¹æ³•
        """
        qreg = encoded_qc.qreg

        # æ·»åŠ å˜åˆ†åˆ†æå±‚
        for layer in range(self.n_layers):
            # æ¯ä¸€å±‚åº”ç”¨å‚æ•°åŒ–æ—‹è½¬é—¨
            for qubit in range(len(qreg)):
                # åº”ç”¨RX, RY, RZæ—‹è½¬é—¨
                angle_x = np.random.uniform(0, 2*np.pi)
                angle_y = np.random.uniform(0, 2*np.pi)
                angle_z = np.random.uniform(0, 2*np.pi)

                encoded_qc.add(RX, qreg[qubit], paras=[angle_x])
                encoded_qc.add(RY, qreg[qubit], paras=[angle_y])
                encoded_qc.add(RZ, qreg[qubit], paras=[angle_z])

            # æ·»åŠ çº ç¼ é—¨
            if layer < self.n_layers - 1:  # æœ€åä¸€å±‚ä¸æ·»åŠ çº ç¼ 
                self._add_entanglement_layer(encoded_qc, qreg)

        # æ·»åŠ æœ€ç»ˆçš„ç‰¹å¾æå–å±‚
        for i in range(len(qreg)):
            encoded_qc.add(H, qreg[i])
            angle = np.pi / 4  # å›ºå®šè§’åº¦
            encoded_qc.add(RY, qreg[i], paras=[angle])

        return encoded_qc

    def _add_entanglement_layer(self, qc: QuantumCircuit, qreg: QuantumRegister):
        """
        æ·»åŠ çº ç¼ å±‚ - åŸºäºsingle_agentçš„æ–¹æ³•
        """
        # ç¯å½¢çº ç¼ ï¼šæ¯ä¸ªé‡å­æ¯”ç‰¹ä¸ä¸‹ä¸€ä¸ªé‡å­æ¯”ç‰¹çº ç¼ 
        for i in range(len(qreg) - 1):
            qc.add(CNOT, qreg[i+1], qreg[i])

        # æœ€åä¸€ä¸ªä¸ç¬¬ä¸€ä¸ªçº ç¼ ï¼Œå½¢æˆç¯
        if len(qreg) > 1:
            qc.add(CNOT, qreg[0], qreg[len(qreg)-1])

    def _execute_single_quantum_circuit(self, qc: QuantumCircuit) -> Dict[str, int]:
        """
        æ‰§è¡Œå•ä¸ªé‡å­çº¿è·¯ - single_agentçš„æ­£ç¡®æ–¹å¼
        å…³é”®ï¼šåªè°ƒç”¨ä¸€æ¬¡backend.apply()ï¼
        """
        # æ·»åŠ æµ‹é‡é—¨
        qreg = qc.qreg
        creg = qc.creg

        for i in range(len(qreg)):
            qc.add(MEASURE, qreg[i], creg[i])

        try:
            # ç¡®ä¿åç«¯å¯ç”¨
            if self.backend is None:
                self._initialize_backend()

            if self.backend is None:
                logger.warning("é‡å­åç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
                return self._generate_fallback_results(len(qreg))

            # å…³é”®ï¼šåªæ‰§è¡Œä¸€æ¬¡ï¼
            logger.info(f"ğŸ”¬ æ‰§è¡Œå•ä¸ªé‡å­çº¿è·¯: {len(qreg)}é‡å­æ¯”ç‰¹, {self.shots}æ¬¡æµ‹é‡")
            self.backend.apply(qc)
            results = self.backend.run(self.shots)

            # éªŒè¯ç»“æœ
            if not results or not isinstance(results, dict):
                logger.warning("é‡å­æ‰§è¡Œç»“æœæ— æ•ˆï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
                return self._generate_fallback_results(len(qreg))

            logger.info(f"âœ… é‡å­çº¿è·¯æ‰§è¡ŒæˆåŠŸï¼Œè·å¾— {len(results)} ä¸ªæµ‹é‡ç»“æœ")
            return results

        except Exception as e:
            logger.error(f"âŒ é‡å­çº¿è·¯æ‰§è¡Œå¤±è´¥: {e}")
            logger.info("ä½¿ç”¨æ¨¡æ‹Ÿç»“æœæ›¿ä»£")
            return self._generate_fallback_results(len(qreg))



    def _generate_fallback_results(self, n_qubits: int) -> Dict[str, int]:
        """ç”Ÿæˆåå¤‡çš„æ¨¡æ‹Ÿé‡å­æµ‹é‡ç»“æœ"""
        logger.info("ç”Ÿæˆæ¨¡æ‹Ÿé‡å­æµ‹é‡ç»“æœ")

        import random
        results = {}

        # ç”Ÿæˆä¸€äº›éšæœºçš„æµ‹é‡ç»“æœ
        for _ in range(min(self.shots, 100)):  # é™åˆ¶ç»“æœæ•°é‡
            # ç”Ÿæˆéšæœºæ¯”ç‰¹ä¸²
            bit_string = ''.join(random.choice(['0', '1']) for _ in range(n_qubits))
            if bit_string in results:
                results[bit_string] += 1
            else:
                results[bit_string] = 1

        logger.info(f"ç”Ÿæˆäº† {len(results)} ä¸ªæ¨¡æ‹Ÿæµ‹é‡ç»“æœ")
        return results
    
    def _extract_quantum_features(self, tavily_data: Dict[str, Any]) -> List[float]:
        """ä»Tavilyæ•°æ®ä¸­æå–é‡å­ç‰¹å¾"""
        features = []
        
        # ç‰¹å¾1: æŠ¥å‘Šé•¿åº¦ï¼ˆæ ‡å‡†åŒ–ï¼‰
        report_length = len(tavily_data.get('report', ''))
        features.append(min(report_length / 10000.0, 1.0))
        
        # ç‰¹å¾2: æ•°æ®æºæ•°é‡
        references_count = len(tavily_data.get('references', []))
        features.append(min(references_count / 20.0, 1.0))
        
        # ç‰¹å¾3: è´¢åŠ¡æ•°æ®ä¸°å¯Œåº¦
        financial_data = tavily_data.get('financial_data', {})
        financial_richness = len(str(financial_data)) / 1000.0
        features.append(min(financial_richness, 1.0))
        
        # ç‰¹å¾4: æ–°é—»æ•°æ®æ´»è·ƒåº¦
        news_data = tavily_data.get('news_data', {})
        news_activity = len(str(news_data)) / 1000.0
        features.append(min(news_activity, 1.0))
        
        # è½¬æ¢ä¸ºè§’åº¦ç¼–ç  [0, 2Ï€]
        features = [f * 2 * np.pi for f in features]
        
        return features
    

    


    def _clear_backend(self):
        """æ¸…ç†é‡å­åç«¯çŠ¶æ€"""
        try:
            # å°è¯•æ¸…ç†å½“å‰åç«¯
            if hasattr(self.backend, 'clear') and callable(self.backend.clear):
                self.backend.clear()
                logger.debug("é‡å­åç«¯çŠ¶æ€å·²æ¸…ç†")
            elif hasattr(self.backend, 'reset') and callable(self.backend.reset):
                self.backend.reset()
                logger.debug("é‡å­åç«¯å·²é‡ç½®")
            else:
                # é‡æ–°åˆå§‹åŒ–åç«¯
                self._initialize_backend()
                logger.debug("é‡å­åç«¯å·²é‡æ–°åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"æ¸…ç†é‡å­åç«¯æ—¶å‡ºé”™: {e}")
            # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œå¼ºåˆ¶é‡æ–°åˆå§‹åŒ–
            try:
                self.backend = None
                self._initialize_backend()
                logger.info("é‡å­åç«¯å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e2:
                logger.error(f"å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–é‡å­åç«¯å¤±è´¥: {e2}")
                # è®¾ç½®ä¸ºNoneï¼Œåç»­ä½¿ç”¨æ¨¡æ‹Ÿç»“æœ
                self.backend = None
    
    def _analyze_quantum_results(self, measurement_results: Dict[str, int], 
                               companies_quantum_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æé‡å­æµ‹é‡ç»“æœ"""
        quantum_analysis = {}
        total_shots = sum(measurement_results.values())
        
        for company_idx, company_data in enumerate(companies_quantum_data):
            company_name = company_data["name"]
            
            # è®¡ç®—è¯¥å…¬å¸çš„é‡å­ç‰¹å¾
            company_measurements = self._extract_company_measurements(
                measurement_results, company_idx, total_shots
            )
            
            quantum_features = self._compute_quantum_features(company_measurements)
            
            quantum_analysis[company_name] = {
                "quantum_features": quantum_features,
                "measurement_probability": company_measurements.get("probability", 0.0),
                "entanglement_strength": self._compute_entanglement_strength(company_measurements),
                "quantum_advantage_score": self._compute_quantum_advantage_score(quantum_features)
            }

        return quantum_analysis

    def _extract_company_measurements(self, measurement_results: Dict[str, int],
                                    company_idx: int, total_shots: int) -> Dict[str, Any]:
        """æå–ç‰¹å®šå…¬å¸çš„æµ‹é‡ç»“æœ"""
        company_results = {"probability": 0.0, "measurements": []}

        # å…¬å¸ç´¢å¼•çš„äºŒè¿›åˆ¶è¡¨ç¤º
        company_binary = format(company_idx, f'0{self.n_qubits}b')

        for bit_string, count in measurement_results.items():
            if bit_string.startswith(company_binary):
                company_results["measurements"].append((bit_string, count))
                company_results["probability"] += count / total_shots

        return company_results

    def _compute_quantum_features(self, company_measurements: Dict[str, Any]) -> List[float]:
        """è®¡ç®—é‡å­ç‰¹å¾"""
        measurements = company_measurements.get("measurements", [])

        if not measurements:
            return [0.0] * 4

        # ç‰¹å¾1: æµ‹é‡ç†µ
        probabilities = [count for _, count in measurements]
        total = sum(probabilities)
        if total > 0:
            probabilities = [p/total for p in probabilities]
            entropy = -sum(p * np.log2(p + 1e-10) for p in probabilities if p > 0)
        else:
            entropy = 0.0

        # ç‰¹å¾2: æœ€å¤§æ¦‚ç‡
        max_prob = max(probabilities) if probabilities else 0.0

        # ç‰¹å¾3: çŠ¶æ€å¤šæ ·æ€§
        num_states = len(measurements)

        # ç‰¹å¾4: å¹³å‡æ¯”ç‰¹å€¼
        avg_bit_value = 0.0
        if measurements:
            total_weight = 0
            for bit_string, count in measurements:
                bit_value = sum(int(bit) for bit in bit_string) / len(bit_string)
                avg_bit_value += bit_value * count
                total_weight += count
            if total_weight > 0:
                avg_bit_value /= total_weight

        return [entropy, max_prob, float(num_states), avg_bit_value]

    def _compute_entanglement_strength(self, company_measurements: Dict[str, Any]) -> float:
        """è®¡ç®—çº ç¼ å¼ºåº¦"""
        measurements = company_measurements.get("measurements", [])
        if len(measurements) <= 1:
            return 0.0

        probabilities = [count for _, count in measurements]
        total = sum(probabilities)
        if total == 0:
            return 0.0

        probabilities = [p/total for p in probabilities]
        max_entropy = np.log2(len(probabilities))
        actual_entropy = -sum(p * np.log2(p + 1e-10) for p in probabilities if p > 0)

        return actual_entropy / max_entropy if max_entropy > 0 else 0.0

    def _compute_quantum_advantage_score(self, quantum_features: List[float]) -> float:
        """è®¡ç®—é‡å­ä¼˜åŠ¿è¯„åˆ†"""
        if not quantum_features:
            return 0.0

        weights = [0.3, 0.3, 0.2, 0.2]
        normalized_features = []

        for i, feature in enumerate(quantum_features):
            if i == 0:  # ç†µ
                normalized_features.append(min(feature / 3.0, 1.0))
            elif i == 1:  # æœ€å¤§æ¦‚ç‡
                normalized_features.append(feature)
            elif i == 2:  # çŠ¶æ€æ•°
                normalized_features.append(min(feature / 8.0, 1.0))
            else:  # å¹³å‡æ¯”ç‰¹å€¼
                normalized_features.append(feature)

        score = sum(w * f for w, f in zip(weights, normalized_features))
        return min(score, 1.0)

    async def _generate_enhanced_reports(self, tavily_data: Dict[str, Any],
                                       quantum_results: Dict[str, Any],
                                       websocket_manager, job_id) -> Dict[str, Any]:
        """ç”Ÿæˆé‡å­å¢å¼ºçš„æŠ¥å‘Š"""
        if websocket_manager and job_id:
            await websocket_manager.send_status_update(
                job_id, status="processing",
                message="ğŸ§  Generating quantum-enhanced reports..."
            )

        enhanced_reports = {}

        for company_name, tavily_report in tavily_data.items():
            quantum_meta = quantum_results.get(company_name, {})

            # ç”Ÿæˆé‡å­å¢å¼ºåˆ†æ
            quantum_insights = self._generate_quantum_insights(quantum_meta)

            # èåˆæŠ¥å‘Š
            enhanced_report = {
                "company_name": company_name,
                "tavily_report": tavily_report.get("report", ""),
                "quantum_enhanced_analysis": tavily_report.get("report", "") + quantum_insights,
                "analysis_metadata": {
                    "tavily_data": {
                        "company_data": tavily_report.get("company_data", {}),
                        "financial_data": tavily_report.get("financial_data", {}),
                        "industry_data": tavily_report.get("industry_data", {}),
                        "news_data": tavily_report.get("news_data", {}),
                        "references": tavily_report.get("references", [])
                    },
                    "quantum_metadata": {
                        "quantum_features": quantum_meta.get("quantum_features", []),
                        "quantum_advantage_score": quantum_meta.get("quantum_advantage_score", 0.0),
                        "entanglement_strength": quantum_meta.get("entanglement_strength", 0.0),
                        "measurement_probability": quantum_meta.get("measurement_probability", 0.0),
                        "processing_timestamp": datetime.now().isoformat(),
                        "quantum_backend": "wuyue_simulator",
                        "shots_used": self.shots,
                        "quantum_layers": self.n_layers,
                        "total_qubits": self.total_qubits
                    }
                }
            }

            enhanced_reports[company_name] = enhanced_report

        return enhanced_reports

    def _generate_quantum_insights(self, quantum_meta: Dict[str, Any]) -> str:
        """ç”Ÿæˆé‡å­æ´å¯Ÿæ–‡æœ¬"""
        quantum_advantage_score = quantum_meta.get("quantum_advantage_score", 0.0)
        entanglement_strength = quantum_meta.get("entanglement_strength", 0.0)
        measurement_probability = quantum_meta.get("measurement_probability", 0.0)

        insights = f"""

## ğŸ”¬ é‡å­å¹¶è¡Œåˆ†æå¢å¼ºæ´å¯Ÿ

**é‡å­ä¼˜åŠ¿è¯„åˆ†**: {quantum_advantage_score:.3f} (èŒƒå›´: 0-1ï¼Œè¶Šé«˜è¡¨ç¤ºé‡å­è®¡ç®—ä¼˜åŠ¿è¶Šæ˜æ˜¾)
**çº ç¼ å¼ºåº¦**: {entanglement_strength:.3f} (è¡¨ç¤ºä¸å…¶ä»–å…¬å¸çš„å…³è”ç¨‹åº¦)
**é‡å­æµ‹é‡æ¦‚ç‡**: {measurement_probability:.3f} (è¡¨ç¤ºè¯¥å…¬å¸åœ¨é‡å­å åŠ æ€ä¸­çš„æƒé‡)

### é‡å­ç‰¹å¾è§£è¯»

- **é‡å­ä¼˜åŠ¿è¯„åˆ† {quantum_advantage_score:.3f}** {'è¾ƒé«˜' if quantum_advantage_score > 0.6 else 'ä¸­ç­‰' if quantum_advantage_score > 0.3 else 'è¾ƒä½'}ï¼Œ
  è¡¨æ˜è¯¥å…¬å¸çš„ç‰¹å¾åœ¨é‡å­ç©ºé—´ä¸­{'å…·æœ‰æ˜æ˜¾çš„éç»å…¸ç‰¹æ€§' if quantum_advantage_score > 0.6 else 'è¡¨ç°ä¸ºç»å…¸ä¸é‡å­çš„æ··åˆç‰¹æ€§' if quantum_advantage_score > 0.3 else 'ä¸»è¦è¡¨ç°ä¸ºç»å…¸ç‰¹æ€§'}ã€‚

- **çº ç¼ å¼ºåº¦ {entanglement_strength:.3f}** æ˜¾ç¤ºè¯¥å…¬å¸ä¸åŒæ‰¹æ¬¡å…¶ä»–å…¬å¸çš„{'å¼ºå…³è”æ€§' if entanglement_strength > 0.7 else 'ä¸­ç­‰å…³è”æ€§' if entanglement_strength > 0.4 else 'å¼±å…³è”æ€§'}ï¼Œ
  {'å»ºè®®é‡ç‚¹å…³æ³¨è¡Œä¸šæ•´ä½“è¶‹åŠ¿å¯¹è¯¥å…¬å¸çš„å½±å“' if entanglement_strength > 0.7 else 'éœ€è¦å¹³è¡¡è€ƒè™‘è¡Œä¸šå› ç´ å’Œå…¬å¸ä¸ªä½“ç‰¹æ€§' if entanglement_strength > 0.4 else 'è¯¥å…¬å¸ç›¸å¯¹ç‹¬ç«‹ï¼Œæ›´å¤šå—è‡ªèº«åŸºæœ¬é¢é©±åŠ¨'}ã€‚

### é‡å­å¹¶è¡Œå¤„ç†ä¼˜åŠ¿

æœ¬åˆ†æé€šè¿‡é‡å­å åŠ æ€åŒæ—¶å¤„ç†å¤šå®¶å…¬å¸æ•°æ®ï¼Œç›¸æ¯”ä¼ ç»Ÿä¸²è¡Œåˆ†æï¼š
- âœ… **çœŸå¹¶è¡Œ**: åˆ©ç”¨é‡å­å åŠ æ€å®ç°çœŸæ­£çš„åŒæ—¶è®¡ç®—
- âœ… **å…³è”å‘ç°**: é€šè¿‡é‡å­çº ç¼ è‡ªåŠ¨æ•è·å…¬å¸é—´éšå«å…³è”
- âœ… **ç‰¹å¾å¢å¼º**: é‡å­æµ‹é‡æä¾›ä¼ ç»Ÿæ–¹æ³•æ— æ³•è·å¾—çš„æ´å¯Ÿç»´åº¦
- âœ… **æ•°æ®èåˆ**: ç»“åˆTavilyé«˜è´¨é‡æ•°æ®æ”¶é›†å’Œé‡å­è®¡ç®—ä¼˜åŠ¿

*æ³¨ï¼šæœ¬é‡å­åˆ†æåŸºäºwuyueé‡å­æ¨¡æ‹Ÿå™¨ï¼Œä½¿ç”¨{self.total_qubits}ä¸ªé‡å­æ¯”ç‰¹ï¼Œ{self.n_layers}å±‚é‡å­çº¿è·¯ï¼Œ{self.shots}æ¬¡æµ‹é‡ã€‚*
        """

        return insights

    async def _save_to_knowledge_base(self, enhanced_reports: Dict[str, Any],
                                    original_companies: List[Dict[str, str]]) -> Dict[str, Any]:
        """ä¿å­˜åˆ°çŸ¥è¯†åº“"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜å•ä¸ªå…¬å¸æŠ¥å‘Š
        for company_name, report in enhanced_reports.items():
            filename = f"{company_name}_quantum_enhanced_{timestamp}.json"
            filepath = os.path.join(self.company_reports_dir, filename)

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            logger.info(f"ğŸ“ {company_name} é‡å­å¢å¼ºæŠ¥å‘Šå·²ä¿å­˜: {filepath}")

        # ä¿å­˜æ‰¹é‡åˆ†ææ‘˜è¦
        batch_summary = {
            "batch_id": f"quantum_batch_{timestamp}",
            "timestamp": timestamp,
            "analysis_type": "quantum_parallel_enhanced",
            "total_companies": len(enhanced_reports),
            "successful_count": len(enhanced_reports),
            "companies_analyzed": list(enhanced_reports.keys()),
            "quantum_parameters": {
                "total_qubits": self.total_qubits,
                "quantum_layers": self.n_layers,
                "measurement_shots": self.shots,
                "max_companies": self.max_companies
            },
            "quantum_statistics": {
                "avg_quantum_advantage": np.mean([
                    report["analysis_metadata"]["quantum_metadata"]["quantum_advantage_score"]
                    for report in enhanced_reports.values()
                ]),
                "avg_entanglement_strength": np.mean([
                    report["analysis_metadata"]["quantum_metadata"]["entanglement_strength"]
                    for report in enhanced_reports.values()
                ])
            },
            "input_companies": original_companies,
            "reports_location": self.company_reports_dir
        }

        batch_filename = f"quantum_batch_analysis_{timestamp}.json"
        batch_filepath = os.path.join(self.batch_results_dir, batch_filename)

        with open(batch_filepath, 'w', encoding='utf-8') as f:
            json.dump(batch_summary, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ“Š é‡å­æ‰¹é‡åˆ†ææ‘˜è¦å·²ä¿å­˜: {batch_filepath}")
        return batch_summary
